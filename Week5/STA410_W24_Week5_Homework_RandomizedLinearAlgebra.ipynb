{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb9cc28",
   "metadata": {},
   "source": [
    "# STA410 Week 5 Programming Assignment (5 points -- rescaled to 2 points)\n",
    "\n",
    "0. **Paired or individual assignment.** Create code solutions for these assignments either individually or in the context of a paired effort. \n",
    "\n",
    "   >  Seek homework partners in class, in course discussion board on piazza, etc.   \n",
    " \n",
    "    \n",
    "1. **Paired students each separately submit their (common) work, including (agreeing) contribution of work statements for each problem.**  \n",
    "  \n",
    "   > Students must work in accordance with the [University of Torontoâ€™s Code of Behaviour on Academic Matters](https://governingcouncil.utoronto.ca/secretariat/policies/code-behaviour-academic-matters-july-1-2019) (and see also http://academicintegrity.utoronto.ca.); however, students working in pairs may share work without restriction within their pair. Getting and sharing \"hints\" from other classmates is encouraged; but, the eventual code creation work and submission must be your own individual or paired creation.\n",
    "      \n",
    "2. **Do not delete, replace, or rearranged cells** as this erases `cell ids` upon which automated code tests are based.\n",
    "\n",
    "   > The \"Edit > Undo Delete Cells\" option in the notebook editor might be helpful; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook).\n",
    "  >> ***If you are working in any environment other than*** [UofT JupyterHub](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master), [Google Colab](https://colab.research.google.com/github/pointOfive/sta410hw0/blob/master/sta410hw0.ipynb), or [UofT JupyterLab](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master&urlpath=/lab/tree/sta410hw0), your system must meet the following versioning requirements \n",
    "   >>\n",
    "   >>   - [notebook format >=4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) \n",
    "   >>   - jupyter [notebook](https://jupyter.org/install#jupyter-notebook) version [>=6.2](https://jupyter-notebook.readthedocs.io/en/stable/) for \"classic\" notebooks served by [jupyterhub](https://jupyterhub.readthedocs.io/en/stable/quickstart.html)\n",
    "   >>   - [jupyterlab](https://jupyter.org/install) version [>=3.0.13](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13) for \"jupyterlab\" notebooks  \n",
    "   >>    \n",
    "   >> otherwise `cell ids` mat not be supported and you will not get any credit for your submitted homework.\n",
    "   >>\n",
    "   >> You may check if `cell ids` are present and working by running the following command in a cell \n",
    "   >>\n",
    "   >> `! grep '\"id\":' <path/to/notebook>.ipynb`\n",
    "   >>\n",
    "   >> and making sure the `cell ids` **do not change** when you save your notebook.\n",
    "   \n",
    "3. ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked.\n",
    "\n",
    " \n",
    "4. **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. \n",
    "\n",
    "  > Run time errors include, e.g., unassigned variables, mismatched parentheses, and any code which does not work when the notebook cells are sequentially run, even if it was provided for you as part of the starter code. ***It is best to restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "  >\n",
    "  > - The `try`-`except` block syntax catches runtime errors and transforms them into `exceptions` which will not cause subsequent automated code tests to fail.  \n",
    "\n",
    "\n",
    "5. **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    "\n",
    "   > ***Comment out ALL jupyter shortcut commands***, e.g., `# ! python script.py 10` or `# %%timeit` in submitted notebooks.\n",
    "\n",
    "\n",
    "6. **Python library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Importing additional libraries will cause subsequent automated code tests to fail.\n",
    "\n",
    "  > Unless a problem instructs differently, you may use any functions available from the libraries imported in the starter code; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary, i.e., base Python and standard Python modules).\n",
    "\n",
    "\n",
    "7. You are encouraged to adapt code you find available online into your notebook; however, if you do so please provide a link to the utilized resource. ***If failure to cite such references is identified and confirmed, your mark will be immediately reduced to 0.***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adab7cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv, solve, cholesky, svd, qr\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.linalg import solve_triangular\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da00226",
   "metadata": {},
   "source": [
    "# Problem 0 (required)\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb188173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee6bf4",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems? Assign one of the following into each of the `Problem_X` variables below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32209794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Problem_1 = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919fe5e3",
   "metadata": {},
   "source": [
    "# Problem 1 (5 points)\n",
    "\n",
    "***Randomized SVD*** addresses the $X_{n\\times p} = U_{n \\times p}D_{p \\times p}V^T_{p \\times p} = U_{n \\times r}D_{r \\times r}V^T_{p \\times r}$ decomposition when $n$ and $p$ together are prohibitively large, but $r<<p$.\n",
    "\n",
    "- The ***SVD*** of an $n \\times p$ matrix has complexity $O(n\\times p \\times \\min(n, p))$\n",
    "- The ***QR decomposition*** of an $n \\times p$ matrix also has complexity $O(n\\times p \\times \\min(n, p))$\n",
    "\n",
    "> See `STA410_W24_Week5_Demo_LeastSquares` and/or `STA410_W24_Week5_Extra_SpeedAndBigOAlgorithmicComplexity` for a discussion of algorithmic complexity.\n",
    "\n",
    "The ***Randomized SVD*** works as follows.\n",
    "1. A random matrix $P_{p\\times r}$ is generated\n",
    "2. $Z_{n\\times r} = X_{n\\times p}P_{p\\times r}$ is computed\n",
    "\n",
    "   which \"randomly samples\" the column space of $X$ ($r$ samples which are the random weighted combinations of the columns of $X$)\n",
    "   \n",
    "   \n",
    "3. The ***QR decomposition*** $Z_{n\\times r}=Q_{n\\times r}R_{r\\times r}$ is computed\n",
    "\n",
    "   so $Q$ is an ***orthogonal basis*** for $Z$, and also for $X$ since $\\text{rank}(X)=r$\n",
    "   \n",
    "   \n",
    "4. $X$ is now projected onto the ***orthogonal directions*** $Q$ as $Y_{r \\times p}=Q^TX$\n",
    "5. The ***SVD*** $Y_{r \\times p} = \\underset{r \\times r}{U_Y} \\underset{r \\times r}{D_Y} \\underset{r \\times p}{V_Y^T}$ is then computed\n",
    "\n",
    "   > and it can be seen that for the original $U_{n \\times r}D_{r \\times r}V^T_{p \\times r} = X_{n\\times p}$ ***SVD*** \n",
    "   > - $D_Y\\approx D_{r \\times r}$\n",
    "   > - columns $[Q_{n \\times r} U_Y{}_{r \\times p}]_{\\cdot j} \\approx \\pm[U_{n \\times p}]_{\\cdot j}$\n",
    "   > - columns $[\\underset{p \\times r}{V_Y{}}]_{\\cdot j} \\approx \\pm[V_{p \\times p}]_{\\cdot j}$ for $j=1,\\cdots,r$\n",
    "   >\n",
    "   > such that, finally\n",
    "   \n",
    "6. $X \\approx Q U_Y D_Y V_Y^T$ which required computations based on $Z_{n\\times r}$ and $Y_{r \\times p}$  instead of $X_{n\\times p}$ when $r << p$\n",
    "\n",
    "   so long as the column space of $Z$ is representative of the column space of $X$, which the random project matrix $P_{p\\times r}$ can guarantee for sufficiently large $r$ in large $X_{n \\times p}$ contexts.\n",
    "\n",
    "\n",
    "In the end this is simply seen to be projecting $X$ into a lower dimensional space which can accurately represent $X$ using $Q^T$, performing the desired computations in that lower dimensional space (where they're less expensive), and the projecting the result back out to the original space with $Q$.\n",
    "\n",
    "***Hints:*** \n",
    "\n",
    "- ***Randomized SVD*** is a technique that comes from the emerging framework of ***Randomized linear algrebra*** which is based on leveraging \"central limit\"-like properties of random matrices (like $P$ here).<!--; but, you can look into this topic further at a later time if you're interested. For now, your task is the implement the methology described above, so stay focussed on doing just that.-->\n",
    "\n",
    "- Here's a [13-minute youtube video](https://www.youtube.com/watch?v=fJ2EyvR85ro) presenting ***Randomized SVD*** upon which this problem is based.  <!--**Please mute your computer or use headphones if you play the video;** *and, don't forget about 1.5x and 2x video speeds to make your review of the video extra efficient.*--> <!-- That said, you may find it helpful to review another presentation of this material just to gain some additional comfort about generally what's going on as you begin diving into this problem.--> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f9b9d",
   "metadata": {},
   "source": [
    "## Problem 1 Questions 0-2 (1.75 points)\n",
    "\n",
    "0. (0.25 points) Use `np.mean` and `np.std` (both with default values) to center and scale the columns of `X` \n",
    "\n",
    "    ```python\n",
    "X = sm.datasets.get_rdataset(\"mtcars\").data.values\n",
    "    ```\n",
    "\n",
    "    so that they have *mean* $0$ and *standard deviation* $1$ and assign this result to the variable `Xtilde`.\n",
    "    \n",
    "    ***WARNING:*** `_Xtilde = (_X - np.mean(_X))/np.std(_X)` ***DOES NOT*** accomplish this. Adjusting the above to include the `axis` parameter of `np.mean` and `np.std` with an appropriate setting would produce the correct result.\n",
    "    \n",
    "\n",
    "1. (0.5 points) Consider the ***condition number*** of `X` and `Xtilde` with `np.linalg.cond` and then use the imported `svd` function to visually compare the ***singular values*** of the ***SVD*** of `X` and `Xtilde` using `plt.plot(np.log(D),'.')` where  `D` is the `np.array` (one dimensional vector) of ***singular values*** returned by the `svd` function. Which of the following most accurately describes this comparison?\n",
    "\n",
    "    1. `X` has a better ***condition number*** than `Xtilde` because `X` has a more extreme/outlying ***singular value*** meaning centering and scaling isn't beneficial\n",
    "    2. `X` has a better ***condition number*** than `Xtilde` because `Xtilde` has a more extreme/outlying ***singular value*** meaning centering and scaling isn't beneficial\n",
    "    3. `X` has a worse ***condition number*** than `Xtilde` because `X` has a more extreme/outlying ***singular value*** meaning centering and scaling is beneficial\n",
    "    4. `X` has a worse ***condition number*** than `Xtilde` because `Xtilde` has a more extreme/outlying ***singular value*** meaning centering and scaling is beneficial\n",
    "    \n",
    "\n",
    "2. For the random `P` matrix below, complete steps 2-6 of the ***Randomized SVD*** procedure\n",
    "\n",
    "    ```python\n",
    "p,r = Xtilde.shape[1],5\n",
    "np.random.seed(10)\n",
    "P = stats.norm().rvs(size=(p,r))\n",
    "    ```\n",
    "\n",
    "    and assign the intermediate variables of the procedure to the corresponding variables `Z` (0.25 points), `Q` and `R` (0.25 points), `Y` (0.25 points), `U_Y`, `D_Y`, and `Vt_Y` (0.25 points).\n",
    "    \n",
    "***Hints:***\n",
    "- The first problem of centering and scaling the data is very important since all subsequent calculations depend on this being done correctly!\n",
    "- The `D` above is considered to be a one dimensional vector `np.array` which is what the `svd` function returns by default.\n",
    "- The same is generally true of `D_Y`; so, when actually computing the matrix multiplication steps you can convert this to a (two dimensional `np.array`) matrix using `np.diag(D_Y)`; or, you can use the broadcasting formulation of the necessary multiplications as has been emphasized in course homework. When assigning the `D_Y` object it may be saved as either the default one dimensional vector `np.array` format, or the two dimensional `np.array` matrix format.  The autotester will check the `shape` first to determine which format these are stored in, and then test them based on that.\n",
    "- Be mindful of the `full_matrices=[True|False]` argument of the `svd` function so that the dimension of the returned matrices is as prescribed by the ***Randomized SVD*** procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b743b3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X = sm.datasets.get_rdataset(\"mtcars\").data.values # Assign X as specified above\n",
    "U,D,V = None,None,None # Assign these using the imported `svd` function\n",
    "\n",
    "# 0.25 points [format: same shape as `X` but with mean 0 and standard deviation 1 columns]\n",
    "Xtilde = None # Standardized X\n",
    "\n",
    "U_Xtilde,D_Xtilde,V_Xtilde = None,None,None# Assign these using the imported `svd` function\n",
    "# etc.\n",
    "\n",
    "# 0.5 points [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q1 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until all variables are assigned values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D,'.')\n",
    "\n",
    "# Any used `D` variable must have been assigned a value to avoid a run time error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ba628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f475e6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.25 points each [format: matrix operations or results form appropriate function calls]\n",
    "Z = None # a matrix multiplication\n",
    "Q, R = None,None #None,None # Assign these using the imported `qr` function\n",
    "Y = None # None # a matrix multiplication\n",
    "U_Y, D_Y, Vt_Y = None,None,None # Assign these using the imported `svd` function with `full_matrices=False`\n",
    "\n",
    "# All variables must be assigned values to avoid run time errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ef83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84105028",
   "metadata": {},
   "source": [
    "## Problem 1 Question 3 (0.25 points)\n",
    "\n",
    "The figures below can be used to see how well the ***Randomized SVD*** procedure can recover `X` and the ***singular values*** for \n",
    "\n",
    "```python\n",
    "p,r = Xtilde.shape[1],5\n",
    "np.random.seed(10)\n",
    "P = stats.norm().rvs(size=(p,r))\n",
    "```\n",
    "\n",
    "3. (0.25 points) Which of the following is the smallest ratio of `r` to `p` for which `np.abs(Xtilde-((Q@U_Y)*D_Y)@Vt_Y).sum()/np.abs(Xtilde).sum()` is less than 0.2?\n",
    "\n",
    "    1. 5/11\n",
    "    2. 6/11\n",
    "    3. 7/11\n",
    "    4. 8/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1cb2a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.25 points [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q3 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q3` variable is assigned a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(11.5,5))\n",
    "ax[0].plot([0,D_Y.max()],[0,D_Y.max()])\n",
    "ax[0].plot(D[:r],D_Y,'.'); ax[0].set_title(\"Standardized Singular Values\")\n",
    "ax[1].plot(Xtilde.ravel(), (((Q@U_Y)*D_Y)@Vt_Y).ravel(),'.'); ax[1].set_title(\"X Versus Reconstituted X Values\")\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(5,5))\n",
    "fig.subplots_adjust(right=0.8)\n",
    "im = ax[0].imshow(Xtilde, cmap='PiYG', vmax=np.abs(Xtilde).max(), vmin=-np.abs(Xtilde).max()); ax[0].set_title(\"X\")\n",
    "ax[1].imshow(Xtilde-(((Q@U_Y)*D_Y)@Vt_Y), cmap='PiYG', vmax=np.abs(Xtilde).max(), vmin=-np.abs(Xtilde).max())\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7]); ax[1].set_title(\"X Residuals\")\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "np.abs(Xtilde-((Q@U_Y)*D_Y)@Vt_Y).sum()/np.abs(Xtilde).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971f0b1",
   "metadata": {},
   "source": [
    "## Problem 1 Questions 4-5 (1 point)\n",
    "\n",
    "Center and scale the columns of the new data\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "X, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=10)\n",
    "```\n",
    "\n",
    "and assign this data into a new `Xtilde`. Then consider various choices for `r` for the ***Randomized SVD*** procedure in the same manner as above based on\n",
    "\n",
    "```python\n",
    "p,r = Xtilde.shape[1],5\n",
    "np.random.seed(10)\n",
    "P = stats.norm().rvs(size=(p,r))\n",
    "```\n",
    "\n",
    "4. (0.5 points) Which of the following is the smallest ratio of `r` to `p` for which `np.abs(Xtilde-((Q@Q_Y)*D_Y)@Vt_Y).sum()/np.abs(Xtilde).sum()` is less than 0.2?\n",
    "\n",
    "    1. 100/400\n",
    "    2. 200/400\n",
    "    3. 300/4096\n",
    "    4. 400/4096\n",
    "    \n",
    "    \n",
    "5. (0.5 points) Which of the two data sets does the ***Randomized SVD*** procedure provide the most computational benefit for?\n",
    "\n",
    "    1. The `statsmodels` `mtcars` data since the ***SVD*** can be recovered at the 0.2 threshold with the smallest `r`\n",
    "    2. The `sklearn` `fetch_olivetti_faces` data since the ***SVD*** can be recovered at the 0.2 threshold for `r` a small fraction of `p`\n",
    "    3. The `sklearn` `fetch_olivetti_faces` data since `n` > `p` for this data set\n",
    "    4. The `statsmodels` `mtcars` data since it is a smaller data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee63bc",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q4 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q5 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "\n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q4` and `p1q5` variable are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d82317",
   "metadata": {},
   "source": [
    "## Problem 1 Question 6-7 (1 point)\n",
    "\n",
    "6. (0.5 points) Assuming $r<p<n$, what is the ***Big O computational complexity*** of the ***Randomized SVD*** procedure (without computing `((Q@U_Y)*D_Y)@Vt_Y` $\\approx$ `X`)?\n",
    "\n",
    "    1. $O(pr^2)$    \n",
    "    2. $O(nr^2)$\n",
    "    3. $O(npr)$\n",
    "    4. $O(np^2)$\n",
    "    \n",
    "  > ***Hint***: *for the operations $A_{n\\times p } x_{p \\times 1} + A_{n\\times p } x_{p \\times 1}$ it is $O(np) + O(np) + O(n) = O(np)$; so, for* ***Randomized SVD*** *you need to determine the* ***Big O computational complexity*** *of each of the necessary steps of the algorithm, and then the largest of these is the complexity of the procedure.*\n",
    "    \n",
    "    \n",
    "7. Will computing the ***Randomized SVD*** will be faster than computing ***SVD***? \n",
    "\n",
    "    1. Yes, if the ***Big $O$ computational complexity*** of ***Randomized SVD*** is less than ***SVD***\n",
    "    2. It will depend on the data set\n",
    "    3. Yes, becaues it avoids doing any ***SVD*** computations and instead only does ***QR*** ***decompositions***\n",
    "    4. Yes, because $O(pr^2)<O(np^2)$\n",
    "    \n",
    "\n",
    "  > ***Hint:*** Review the problem prompt and determine the ***Big $O$ Complexity*** of each of the steps of the ***randomized SVD*** procedure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adead5c1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q6 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q7 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "\n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q6` and `p1q7` variable are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78630575",
   "metadata": {},
   "source": [
    "## Problem 1 Question 8-9 (1 point)\n",
    "\n",
    "8. (0.5 points) For $r<p$, what is true about $QU_YD_YVt_Y$ and $X$?\n",
    "\n",
    "    1. $QU_YD_YVt_Y$ has a larger or undefined ***condition number***\n",
    "    2. $X$ has a larger ***condition number***\n",
    "    3. $X$ and $QU_YD_YVt_Y$ have the same ***condition number***\n",
    "    4. Both are ***full rank*** (***non-singular***) matrices\n",
    "    \n",
    "    \n",
    "9. What is true about the theoretical ***condition number*** of $Q$ and $U_Y$?\n",
    "\n",
    "    1. $Q$ has a larger ***condition number*** than $U_Y$ because $Q$ is from a ***QR decomposition***\n",
    "    2. $U_Y$ has a larger ***condition number*** than $Q$ because $U_Y$ is from an ***SVD***\n",
    "    3. $Q$ and $U_Y$ have different ***condition numbers*** because $Z_{n\\times r}$ and $Y_{r\\times p}$ have different ranks\n",
    "    4. Unless $X$ is ***orthogonal***, $Q$ and $U_Y$ will have a smaller ***condition number*** than $X$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4ad00",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q8 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q9 = None # <\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "\n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q8` and `p1q9` variable are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f1d66",
   "metadata": {},
   "source": [
    "## Problem 1 Bonus Question 10 (1 point) [but maximium points on Problem 1 is still 5]\n",
    "\n",
    "10. Use the ***Gram-Schmidt orthogonalization method*** provided below to create a ***QR decomposition*** for `X` defined as follows.\n",
    "\n",
    "```python\n",
    "np.random.seed(10); n,p = 100,10\n",
    "X = stats.norm.rvs(size=(n,p))\n",
    "```\n",
    "\n",
    "Let $Q$ be the ***Gram-Schmidt orthogonalization*** of $X$; then, $R$ is ***upper triangular matrix*** such that $QR=X$. You may not use the imported `qr` function to compute $Q$ and $R$; but, you can use it to check your results.\n",
    "\n",
    "***Hints:*** \n",
    "- The imported `solve` function only works for ***square*** `A` in `solve(A,b)`; but, `np.linalg.lstsq` will work for ***non-square*** and even ***non-full rank*** `A` (though of course we expect `Q` to be ***full rank***).\n",
    "- `solve(A,b)` or `np.linalg.lstsq(A,b)` find $x$ solving $Ax = b$ (if possible, or a least squares optimal $Ax \\approx b$ when not possible in the latter case); but, they can also address the multi-vector $AX = B$ version of this task as well.\n",
    "    - All of these problems seek to find linear combinations of the columns of $A$ which produce (or approximate) the vector $b$, or collection of vectors $B$.\n",
    "    - This problem requires essentially no coding, and instead just using `gram_schmidt` and `np.linalg.lstsq` correctly.\n",
    "- Use `np.round(qr(X)[1],2)` to see what `R` should look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08e703",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def is_linearly_independent_columns(X):\n",
    "    # return False if Rank(X)<p or n<p; otherwise, True\n",
    "    if X.shape[1] <= X.shape[0] and np.linalg.matrix_rank(X) == X.shape[1]:\n",
    "        return True\n",
    "\n",
    "def gram_schmidt(X):\n",
    "    \n",
    "    \"\"\"\n",
    "    X       : n linearly independent column vectors\n",
    "              (np.array) [X[:,0], X[:,1], ... , X[:,p-1]]), X.shape=(n,p)\n",
    "              or raises a \"Linearly Dependent Columns\" ValueError if Rank < p or Rank > n   \n",
    "    returns : n orthonormalized column vectors, \n",
    "              (np.array) [Xtilde[:,0], Xtilde[:,1], ... , Xtilde[:,p-1]], Xtilde.shape=(n,p)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not is_linearly_independent_columns(X):\n",
    "        raise ValueError('Linearly Dependent Columns')\n",
    "\n",
    "    # make sure the data type is float not int which won't work\n",
    "    X = np.array(X, dtype=float)# X=np.array([[1,1],[1,2]]); X[:,0] = np.array([0.5,.5])\n",
    "    \n",
    "    Xtilde = X.copy()\n",
    "    \n",
    "    Xtilde[:,0] = X[:,0]/X[:,0].dot(X[:,0])**0.5\n",
    "    for l in range(1, X.shape[1]):\n",
    "        for j in range(l, X.shape[1]):\n",
    "            Xtilde[:,j] = Xtilde[:,j] - Xtilde[:,l-1]*(Xtilde[:,j].dot(Xtilde[:,l-1]))\n",
    "        Xtilde[:,l] = Xtilde[:,l]/Xtilde[:,l].dot(Xtilde[:,l])**0.5\n",
    "    return Xtilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9019f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616df4c2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point [format: np.array matrix]\n",
    "\n",
    "#p1q10 = R\n",
    "# Uncomment the above to assign R to p1q10\n",
    "\n",
    "# This cell will produce a runtime error if the `p1q10` variable is uncommented but unassigned a value"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
