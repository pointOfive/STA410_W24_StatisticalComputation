{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3aa0add",
   "metadata": {},
   "source": [
    "# STA410 Week 6 Programming Assignment (5 points)\n",
    "\n",
    "0. **Paired or individual assignment.** Create code solutions for these assignments either individually or in the context of a paired effort. \n",
    "\n",
    "   >  Seek homework partners in class, in course discussion board on piazza, etc.   \n",
    " \n",
    "    \n",
    "1. **Paired students each separately submit their (common) work, including (agreeing) contribution of work statements for each problem.**  \n",
    "  \n",
    "   > Students must work in accordance with the [University of Torontoâ€™s Code of Behaviour on Academic Matters](https://governingcouncil.utoronto.ca/secretariat/policies/code-behaviour-academic-matters-july-1-2019) (and see also http://academicintegrity.utoronto.ca.); however, students working in pairs may share work without restriction within their pair. Getting and sharing \"hints\" from other classmates is encouraged; but, the eventual code creation work and submission must be your own individual or paired creation.\n",
    "      \n",
    "2. **Do not delete, replace, or rearranged cells** as this erases `cell ids` upon which automated code tests are based.\n",
    "\n",
    "   > The \"Edit > Undo Delete Cells\" option in the notebook editor might be helpful; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook).\n",
    "  >> ***If you are working in any environment other than*** [UofT JupyterHub](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master), [Google Colab](https://colab.research.google.com/github/pointOfive/sta410hw0/blob/master/sta410hw0.ipynb), or [UofT JupyterLab](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master&urlpath=/lab/tree/sta410hw0), your system must meet the following versioning requirements \n",
    "   >>\n",
    "   >>   - [notebook format >=4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) \n",
    "   >>   - jupyter [notebook](https://jupyter.org/install#jupyter-notebook) version [>=6.2](https://jupyter-notebook.readthedocs.io/en/stable/) for \"classic\" notebooks served by [jupyterhub](https://jupyterhub.readthedocs.io/en/stable/quickstart.html)\n",
    "   >>   - [jupyterlab](https://jupyter.org/install) version [>=3.0.13](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13) for \"jupyterlab\" notebooks  \n",
    "   >>    \n",
    "   >> otherwise `cell ids` mat not be supported and you will not get any credit for your submitted homework.\n",
    "   >>\n",
    "   >> You may check if `cell ids` are present and working by running the following command in a cell \n",
    "   >>\n",
    "   >> `! grep '\"id\":' <path/to/notebook>.ipynb`\n",
    "   >>\n",
    "   >> and making sure the `cell ids` **do not change** when you save your notebook.\n",
    "   \n",
    "3. ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked.\n",
    "\n",
    " \n",
    "4. **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. \n",
    "\n",
    "  > Run time errors include, e.g., unassigned variables, mismatched parentheses, and any code which does not work when the notebook cells are sequentially run, even if it was provided for you as part of the starter code. ***It is best to restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "  >\n",
    "  > - The `try`-`except` block syntax catches runtime errors and transforms them into `exceptions` which will not cause subsequent automated code tests to fail.  \n",
    "\n",
    "\n",
    "5. **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    "\n",
    "   > ***Comment out ALL jupyter shortcut commands***, e.g., `# ! python script.py 10` or `# %%timeit` in submitted notebooks.\n",
    "\n",
    "\n",
    "6. **Python library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Importing additional libraries will cause subsequent automated code tests to fail.\n",
    "\n",
    "  > Unless a problem instructs differently, you may use any functions available from the libraries imported in the starter code; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary, i.e., base Python and standard Python modules).\n",
    "\n",
    "\n",
    "7. You are encouraged to adapt code you find available online into your notebook; however, if you do so please provide a link to the utilized resource. ***If failure to cite such references is identified and confirmed, your mark will be immediately reduced to 0.***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e256d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unless a problem instructs differently, you may use any functions available from the following library imports\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48de6e",
   "metadata": {},
   "source": [
    "# Problem 0 (required)\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78081a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b3e6",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems? Assign one of the following into each of the `Problem_X` variables below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589b6a8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Problem_1 = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca994284",
   "metadata": {},
   "source": [
    "# Problem 1 (5 points)\n",
    "\n",
    "Complete the ***gradient descent optimization algorithm*** with ***TensorFlow*** below for \n",
    "- parameters $A_1, b_1, A_2,$ and $b_2$ of the model\n",
    "- $\\hat y = f_{A_1,b_1,A_2,b_2}(x) = \\big( (A_2(A_1 x + b_1)_+ + b_2)_+ \\big)$\n",
    "- minimizing the (loss objective) function $||\\epsilon||_2 = ||y-f_{A_1,b_1,A_2,b_2}(x)||_2$\n",
    "\n",
    "where $(\\cdot)_+$ is the so-called ***ReLU activation function*** which sets all negative values within the object to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a4b39",
   "metadata": {},
   "source": [
    "The `f` function above specifies the standard form of a \"vanilla\" (shallow) two layer ***neural network***\n",
    "where $A_jx + b_j$ are ***affine transformations*** and $\\{q_j\\circ (A_jy_j + b_j)\\}$ are [elementwise](https://math.stackexchange.com/questions/2324764/notation-for-element-wise-function-application) non-linear transformation of affine transformations.\n",
    "\n",
    "A \"vanilla\" ***deep neural network*** is the extension of such sequence of alternating applications of (a) affine transformations and (b) elementwise non-linearly transformations of the previous affine transformation  for some large $K$ \n",
    "\n",
    "$$q_K \\circ (A_K \\{ \\cdots \\{q_2 \\circ (A_2\\{q_1 \\circ (A_1x + b_1)\\} + b_2)\\} \\cdots \\} + b_K)$$\n",
    "\n",
    "> The \"***architecture***\" of a ***neural network*** refers to the details of extensions beyond this form which increase sophistication and capability for various purposes. \n",
    "> - The primary advance in ***neural networks*** has been the ability to create ***deep neural network architectures*** which do not suffer from the \"***vanishing gradient***\" problem (that the ***chain rule*** basis of ***backpropegation*** algorithm used to compute ***gradients*** for optimization of ***deep neural network*** is the product of many partial derivatives together which can multiplicatively \"vanish to zero\"), and to create ***deep neural network*** specifications that have more ***isotropically*** behaved optimization surfaces, with the key respective methodological advances driving improvements in these regards being introduction of ***ReLU*** activation functions and a technique called ***batch norm***.\n",
    "\n",
    "***Deep neural networks*** are the most flexible (\"***universal***\") function approximation methodology available today. To provide a sense of how flexible and powerful these are, the images below (taken from this [interactive webpage](https://arogozhnikov.github.io/3d_nn/)) demonstrate ***neural network*** functions by animating how they increases accross the input space. Some good resources to continue learning about ***deep neural network***\n",
    "are the [deep learning](https://www.deeplearningbook.org/) and [dive into deep learning](https://d2l.ai/) textbooks. \n",
    "\n",
    "|||||\n",
    "|-|-|-|-|\n",
    "|![](https://s9.gifyu.com/images/SFOrY.gif)|![](https://s9.gifyu.com/images/SFOra.gif)|![](https://s9.gifyu.com/images/SFOrr.gif)|![](https://s9.gifyu.com/images/SFOrZ.gif)|\n",
    "|![](https://s9.gifyu.com/images/SFOrf.gif)|![](https://s9.gifyu.com/images/SFOrt.gif)|![](https://s9.gifyu.com/images/SFOr5.gif)|![](https://s9.gifyu.com/images/SFOrD.gif)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0854e4c8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "alpha,K = 0.01,10\n",
    "d,q1,q2 = 3,2,3\n",
    "x = tf.constant(np.random.normal(size=(d,1)))\n",
    "y = tf.constant(np.random.normal(size=(q2,1)))\n",
    "A1 = tf.Variable(np.random.normal(size=(q1,d)))\n",
    "b1 = tf.Variable(np.random.normal(size=(q1,1)))\n",
    "A2 = tf.Variable(np.random.normal(size=(q2,q1)))\n",
    "b2 = tf.Variable(np.random.normal(size=(q2,1)))\n",
    "\n",
    "arg1 = tf.TensorSpec(shape=x.shape, dtype=tf.float64)\n",
    "arg2 = tf.TensorSpec(shape=A1.shape, dtype=tf.float64)\n",
    "arg3 = tf.TensorSpec(shape=b1.shape, dtype=tf.float64)\n",
    "arg4 = tf.TensorSpec(shape=A2.shape, dtype=tf.float64)\n",
    "arg5 = tf.TensorSpec(shape=b2.shape, dtype=tf.float64)\n",
    "\n",
    "@tf.function(input_signature=(arg1,arg2,arg3,arg4,arg5,))\n",
    "def f(x0, A1, b1, A2, b2):\n",
    "    return None #<f as defined in the problem prompt> <- fix this\n",
    "\n",
    "@tf.function(input_signature=(arg1,arg1,))\n",
    "def loss(y, yhat):\n",
    "    return None #<L2 norm of epsilon> <- fix this\n",
    "\n",
    "# You are not meant to actually fit a model here,\n",
    "# only set up and run the correct code that could fit a model\n",
    "# and then run it for `K` steps\n",
    "# and then assign `p2q0 = loss(x, y, A1, b1, A2, b2)`\n",
    "# the final value of the `loss` function after the `K` steps finish\n",
    "for i in range(K):\n",
    "    # <complete `K` steps of gradient descent>\n",
    "    # <for the `tf.Variable` model parameters>\n",
    "    pass\n",
    "\n",
    "# 1 points [format: `(A1, b1, A2, b2)` with the results of the for loop above after it  \n",
    "#                    implements the gradient descent algorithm for `alpha,K = 0.01,10` ]\n",
    "p1q6 = None #(A1, b1, A2, b2) # the `p1q6` variable name is correct -- it makes sense to assign this here\n",
    "# Uncomment the line above so the result of the gradient descent algorithm for `alpha,K = 0.01,10` is saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7dcde",
   "metadata": {},
   "source": [
    "## Problem 1 question 0-3 (1 point)\n",
    "\n",
    "0. (0.25 points) What is the input and dimesnion of the \"first hidden layer\" $h_1 = (A_1 x + b_1)$ of `f` above?\n",
    "\n",
    "    - A. The input vector $x$ has length 2 and the \"first hidden layer\" output $h_1$ is a vector of length 2\n",
    "    - B. The input vector $x$ has length 2 and the \"first hidden layer\" output $h_1$ is a vector of length 3\n",
    "    - C. The input vector $x$ has length 3 and the \"first hidden layer\" output $h_1$ is a vector of length 2\n",
    "    - D. The input vector $x$ has length 3 and the \"first hidden layer\" output $h_1$ is a vector of length 3\n",
    "\n",
    "\n",
    "1. (0.25 points) Generally speaking, must the dimension of the input $x$ to the ***neural network*** function `f` match the dimension of the output $y$?\n",
    "\n",
    "    - A. Yes, and `q1` should also reflect this same dimension\n",
    "    - B. Yes, but `q1` need not reflect this same dimension\n",
    "    - C. No, so long as `q2` reflects the same dimension as `d`\n",
    "    - D. No, `q2` need not reflect the same dimension as `d` \n",
    "    \n",
    "    \n",
    "2. (0.25 points) Which of the following is true regarding the \"first hidden layer\" $h_1 = (A_1 x + b_1)$ of `f`?\n",
    "\n",
    "    - A. It is an elementwise nonlinear transformation of an (lower dimensional) affine transformation of $x$\n",
    "    - B. It is the input to the \"second hidden layer\" $h_2 = (A_2 h_1 + b_2)$\n",
    "    - C. It is a function of $x$ that is parameterized by $A_1$ and $b_1$ \n",
    "    - D. All of the above\n",
    "\n",
    "\n",
    "3. (0.25 points) Which of the following exactly expresses the (loss objective) function $||\\epsilon||_2$?\n",
    "\n",
    "    - A. $\\sqrt{(y-f_{A_1,b_1,A_2,b_2}(x))^T(y-f_{A_1,b_1,A_2,b_2}(x))}$\n",
    "    - B. $\\sum_{i=1}^n (y_i - f_{A_1,b_1,A_2,b_2}(x_i))$\n",
    "    - C. $\\frac{1}{2}\\sum_{i=1}^n (y_i - f_{A_1,b_1,A_2,b_2}(x)_i)$\n",
    "    - D. $\\frac{1}{2}(y-f_{A_1,b_1,A_2,b_2}(x))^T(y-f_{A_1,b_1,A_2,b_2}(x))$\n",
    "    - E. None of the above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 point (0.25 points each) [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" or \"E\" based on the choices above]\n",
    "p1q0 = None#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q1 = None#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q2 = None#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q3 = None#<\"A\"|\"B\"|\"C\"|\"D\"|\"E\"> \n",
    "# Replace `None` above either \"A\" or \"B\" or \"C\" or \"D\" or \"E\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1d124",
   "metadata": {},
   "source": [
    "## Problem 1 question 4 (1 point)\n",
    "\n",
    "Your `f` function above will be tested for various inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9d709",
   "metadata": {},
   "source": [
    "## Problem 1 question 5 (1 point)\n",
    "\n",
    "Your `loss` function above will be tested for various inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbedd3a",
   "metadata": {},
   "source": [
    "## Problem 1 question 6 (1 point)\n",
    "\n",
    "Your ***gradient descent*** algorithm above will be tested for various input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c396d",
   "metadata": {},
   "source": [
    "## Problem 1 questions 7-10 (1 points)\n",
    "\n",
    "7. (0.25 points) Why is the algorithm coded in this problem different than ***nonlinear Gauss-Seidel***?\n",
    "\n",
    "    - A. Because `f` is a linear function of `x`, not a nonlinear function of `x`\n",
    "    - B. Because each parameter is not cyclically optimized given the value of the others\n",
    "    - C. Because the algorithm coded in this problem is a ***coordinate descent*** algorithm\n",
    "    - D. The algorithm coded in this problem is not different than ***nonlinear Gauss-Seidel***\n",
    "    \n",
    "    \n",
    "8. (0.25 points) If `alpha` was decreased towards zero, what could be adjusted to compensate so that the algorithm maintained an approximately similar level of convergence progress?\n",
    "\n",
    "    - A. `K` could be increased\n",
    "    - B. `b1` and `b2` could be given smaller magnitudes\n",
    "    - C. `A1` and `A2` could be given larger magnitudes\n",
    "    - D. Choices 'A' and 'B' above\n",
    "    \n",
    "    \n",
    "9. (0.25 points) The function under consideration in this problem is\n",
    "\n",
    "  $$\\hat y = f_{A_1,b_1,A_2,b_2}(x) = \\big( (A_2(A_1 x + b_1)_+ + b_2)_+ \\big)$$\n",
    "  \n",
    "  where $(\\cdot)_+$ is the so-called ***ReLU activation function*** which sets all negative values within the object to $0$.\n",
    "  \n",
    "  What is the problem with this as a function for $\\hat y$ predicting $y$? \n",
    "  \n",
    "    - A. It is not a continuous function so it doesn't have derivatives everywhere\n",
    "    - B. It is a nonlinear function so it should not be used to predict $y$\n",
    "    - C. It can only produce positive $\\hat y$ predictions, so it would not work for regression with negative $y$ values \n",
    "    - D. Nothing, this $\\hat y$ will be a reasonable predictor of $y$ as long is the function $f$ is sufficiently flexible    \n",
    "    \n",
    "\n",
    "10. (0.25 points) Which of the following adjustments to $f_{A_1,b_1,A_2,b_2}(x)$ could be supported by ***gradient descent*** using ***TensorFlow***?\n",
    "\n",
    "    - A. $L_2$ \"ridge\" regularization on the $[A_k]_{ij}$ ***weights*** and $[b_k]_{j}$ ***biases*** $\\quad f_{A_1,b_1,A_2,b_2}(x) = (A_2(A_1 x + b_1)_+ + b_2)_+ + \\sum_k A_k^TA_k + b_k^T b_k$\n",
    "    - B. $L_1$ \"lasso\" regularization on the $[A_k]_{ij}$ ***weights*** and $[b_k]_{j}$ ***biases*** $\\quad f_{A_1,b_1,A_2,b_2}(x) = (A_2(A_1 x + b_1)_+ + b_2)_+ + \\sum_k |A_k| + |b_k|$\n",
    "    - C. $f_{A_1,b_1,A_2,b_2}(x)$ can be any function whose partial derivatives with respect to $A_1,b_1,A_2$, and $b_2$ are known for ***TensorFlow AutoDiff***\n",
    "    - D. All of the above\n",
    "    - E. None of the above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c58d3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.25 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q7 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q8 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q9 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q10 = None #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a71dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
